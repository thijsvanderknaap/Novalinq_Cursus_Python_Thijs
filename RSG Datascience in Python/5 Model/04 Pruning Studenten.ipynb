{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "\n",
    "We gaan nu dezelfde dataset trainen en fitten. Maar nu met oog naar de parameters van het model. Daarna zullen we de RandomForest introduceren die veel van het parameter tunen al voor je doet! Echter is het ook hier belangrijk om aandacht te schenken aan het paramter tunen. \n",
    "\n",
    "Haal hieronder de data binnen. Doet dit voor zowel\n",
    "\n",
    "- x_test\n",
    "- y_test\n",
    "- x_train\n",
    "- y_train\n",
    "\n",
    "Zoals het plaatje eerder liet zien zullen we de training set (x_train en y_train) gebruiken om het model te fitten, om het vervolgens te testen op de testset. \n",
    "\n",
    "\n",
    "### Actie! \n",
    "\n",
    "Ja we kunnen het niet vaak genoeg doen.   \n",
    "Haal de titanic dataset binnen onder de naam **TTC**  \n",
    "Haal **x_test, y_test, x_train en y_train** binnen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "TTC = pd.read_csv('data/Titanic.csv', index_col=0)\n",
    "\n",
    "x_test = pd.read_csv('data/x_test.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')\n",
    "x_train = pd.read_csv('data/x_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning waardes.  \n",
    "\n",
    "Pruning is het aanpassen van de grootte van de tree. Wanneer je meer pruned (letterlijke vertaling : snoeit) dan voorkom je dat de boom verder door splitst op nieuwe features. Net als met een regressie lijn die een steeds  polynomialere functie krijgt, kan een boom die minder pruned (dus groter wordt) steeds complexer worden. En we weten: een complexer model heeft een sterke neiging om te overfitten! \n",
    "\n",
    "Hieronder zijn nog een aantal andere parameters die 'getuned' kunnen worden. Neem ze goed door en bedenk je wat voor invloed ze hebben op het model. \n",
    "\n",
    "\n",
    "**Gini vs. Entropy** \n",
    "Mate waarmee de wanorde in een subset word getoetst.\n",
    "Gini cijfer voor totale wanorde is 0.5.\n",
    "Entropy waarde voor totale wanorde is 1.\n",
    "\n",
    "**Splitter** : best (de beste split in overweging nemend alle feautures) of random (de beste split voor een random subset van feautures, afhankelijk van max_feautures).\n",
    "\n",
    "**Max_depth** : maximum diepte van de boom. Ofwel hoevaak mag er gesplit worden, hoeveel rijen nodes mogen er gemaakt worden...\n",
    "\n",
    "**Min_samples_split** : minimum hoeveelheid samples nodig om een internl node te splitsen. default 2.\n",
    "\n",
    "**Min_samples_leaf** : minimum hoeveelheid om een terminal blad te vormen. (deze is gewichtiger dan min_samp_split).\n",
    "\n",
    "**Max_features** : int, float, string or None, optional (default=None)\n",
    "    The number of features to consider when looking for the best split:\n",
    "    \n",
    "**Max_leaf_nodes** : maximum hoeveelheid uiteindelijke bladeren (bladeren worden gekozen met beste eerst methode).\n",
    "\n",
    "**Min_impurity_decrease** : float, optional (default=0.)\n",
    "    En node wordt slechts gespllitst als er een waarde groter dan of gelijk aan deze van gain in puurheid wordt berekend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actie! \n",
    "\n",
    "Vul hieronder verschillende parameter values in en zie wat het doet met de score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zie hieronder alle mogelijke parameters! Kijk naar wat de default value is\n",
    "# en verzin mogelijke ander waardes. \n",
    "\n",
    "DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bijvoorbeeld deze: Je kan ook gelijk zien in de parameters van het model dat het wordt aangepast. \n",
    "\n",
    "DecisionTreeClassifier(max_depth=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kijk wat het doet met de voorspelling van de training set en test set. Is de trainingset vele male hoger? Dan kan er spraken zijn van overfitting! Denk na over wat parameter tuning doet met je voorspellingen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ae762721c2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdecision_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "train_score = decision_tree.score(x_train, y_train)\n",
    "test_score = decision_tree.score(x_test, y_test)\n",
    "\n",
    "print(\"the train score = {}\".format(train_score))\n",
    "print(\"the test score =  {}\".format(test_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actie! \n",
    "\n",
    "Onthoudt de beste parameter instellingen en sla zie hieronder op. Ze komen later wellicht van pas en we zullen ze aan het einde bespreken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC/AUC  \n",
    "\n",
    "ROC (Receiver Operating Characteristic) plot de false possitive rate tegenover de true possitive rate.  \n",
    "AUC, area under de curve geeft aan welke waardes we het best kunnen gebruiken ivm overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC  \n",
    "  \n",
    "  AUC geeft eigenlijk een hoe goed het algoritme is in voorspellen aan de hand van een bepaalde waarde van een parameter.  \n",
    "  Dit kunnen we perfect gebruiken om te besluiten welke waardes goed zijn om overfitten te voorkomen.  \n",
    "  \n",
    "  Als we de verschillende AUC's per waarde van depth tegenover elkaar plotten voor voorspellingen op onze test en train data, kunnen we goed zien hoe behoorlijk ons model aan het overfitten was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fbfbd8805d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5bdfc8f9f580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-461ff68f286f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_depths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dt.fit(x_train, y_train)\n",
    "    \n",
    "    train_pred = dt.predict(x_train)\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_auc.append(roc_auc)\n",
    "    \n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_auc.append(roc_auc)\n",
    "    \n",
    "line1, = plt.plot(max_depths, train_auc, c='b', label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_auc, c='r', label=\"Test AUC\")\n",
    "plt.legend()\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tradeoff.  \n",
    "\n",
    "Hoe dieper we gaan, hoe puurder worden de leave-nodes. Maar de variantie van ons model gaat dan ook erg omhoog!  \n",
    "\n",
    "Variantie en bias zijn twee belangrijke termen binnen Machine Learning algoritmes. Ze geven indicaties op hoe erg je model aan het generaliseren is op de trainingset. Hierbij komen nog twee termen naar boven, namelijk **overfitten** en **underfitten**. Deze termen zijn eerder al benoemd en zullen hier nog even besproken worden. \n",
    "\n",
    "Als je bias hoog is (of zoals gezegd wordt, als je model biased is) dan betekend het dat je model systematisch foute voorspellingen maakt. Hier wordt vaak gesproken van underfitting. Je model is niet goed getrained op de trainingset en is niet representatief voor testdata. \n",
    "\n",
    "Als je variantie hoog is en bias laag, dan betekend het dat je model aan het overfitten is. Zoals te zien in het plaatje zijn de voorspele datapunten niet allemaal in de roos. Vaak is het zo dat des te complexer je model, des te meer je overfit op de training data, waardoor je testdata minder goed wordt voorspelt. Het kan zijn dat de trainingdata niet representatief genoeg is (of een te kleine set) waardoor de features die het model leert niet goed of voldoende zijn om de testdata te voorspellen. \n",
    "\n",
    "![alt text](files/tradoff.png \"Title\")\n",
    "\n",
    "We willen dus een lage-bias lage-variantie. Je kan het als volgt interpreteren: \n",
    "\n",
    "![alt text](files/tradeoff_graph.png \"Title\")\n",
    "\n",
    "je wilt dus een minimun vinden in de opgetelde bias/variantie van een gefitte model. Hieronder zullen we zien hoe je een keuze kan maken in het vinden van goede parameters en features om te voorkomen dat je model overfit op de data.\n",
    "\n",
    "Afgaand op deze grafiek is een Depth van 4 tot 7 zo'n beetje de beste keuze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'min_samples_split')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(2, 150, 148, endpoint=True , dtype=int)\n",
    "\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "\n",
    "for i in min_samples_splits:\n",
    "    dt = DecisionTreeClassifier(max_depth= 7, min_samples_split=i)\n",
    "    dt.fit(x_train, y_train)\n",
    "    \n",
    "    train_pred = dt.predict(x_train)\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_auc.append(roc_auc)\n",
    "    \n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_auc.append(roc_auc)\n",
    "\n",
    "line1, = plt.plot(min_samples_splits, train_auc, c='b', label=\"Train AUC\")\n",
    "line2, = plt.plot(min_samples_splits, test_auc, c='r', label=\"Test AUC\")\n",
    "plt.legend()\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min_samples_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'min_samples_leaf')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_samples_leafs = np.linspace(1, 50, 50, endpoint=True, dtype=int)\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    dt = DecisionTreeClassifier(max_depth = 7, min_samples_split= 78, min_samples_leaf=min_samples_leaf)\n",
    "    dt.fit(x_train, y_train)\n",
    "    \n",
    "    train_pred = dt.predict(x_train)\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    \n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "\n",
    "line1, = plt.plot(min_samples_leafs, train_results, c='b', label=\"Train AUC\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, c='r', label=\"Test AUC\")\n",
    "plt.legend()\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min_samples_leaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 7, min_samples_split= 78, min_samples_leaf=17)\n",
    "dt.fit(x_train, y_train)\n",
    "    \n",
    "y_pred = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.93      0.86        99\n",
      "         1.0       0.89      0.70      0.78        80\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.84      0.81      0.82       179\n",
      "weighted avg       0.84      0.83      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>116</td>\n",
       "      <td>63</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  All\n",
       "True                    \n",
       "0.0         92    7   99\n",
       "1.0         24   56   80\n",
       "All        116   63  179"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(np.asarray(y_test['Survived'] ), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een random forest doet in zekere zin wat de afgelopen tijd hebben uitgevoerd. Het fit een groot aantal bomen met verschillende parameter waardes en verschillende sub-samples van de dataset. De boom functioneert nu in zekere zin zoals een groep mensen een beslissing zouden maken. Iedere boom (of ieder mens) heeft een andere 'mening' (lees: parameters) om een voorspelling te maken. \n",
    "\n",
    "Het model evalueert iedere boom met andere paramter instellingen en input, en neemt hierover een gemiddelde om tot de beste voorspelling te komen. Dit voorkomt ook overfitten. Net zoals dat je een gedeeld mening van een grote groep beter kan nemen dan een enkel persoon, is de gemiddelde voorspellende waarde van een boom genomen om high variance te voorkomen. \n",
    "\n",
    "Random Forest heeft een groot aantal parameters die je kan tunen. \n",
    "\n",
    "    n_estimators=10, \n",
    "    criterion=mse, \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    min_weight_fraction_leaf=0.0, \n",
    "    max_features=auto, \n",
    "    max_leaf_nodes=None, \n",
    "    min_impurity_decrease=0.0, \n",
    "    min_impurity_split=None, \n",
    "    bootstrap=True, \n",
    "    oob_score=False, \n",
    "    n_jobs=1, \n",
    "    random_state=None, \n",
    "    verbose=0, \n",
    "    warm_start=False\n",
    "    \n",
    "    \n",
    "We zullen in gaan op enkele van deze die belangrijk zijn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tr_te(data, parameter):\n",
    "    x = list(range(len(data[0])))\n",
    "    plt.plot(x, data[0])\n",
    "    plt.plot(x, data[1])\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.xlabel(parameter)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators \n",
    "\n",
    "Het aantal bomen dat wordt gefit. Over het algemeen geldt, des te meer bomen, des te beter de voorspelling. Het kost het model wel veel computing power om alles te runnen, er moeten immers veel bomen worden gemaakt! Je bent vaak opzoek naar een punt waarin het aantal estimates voldoende is om je testdata te voorspellen. \n",
    "\n",
    "Hieronder zien we dat er bij 20 toch wel een maximum is bereikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'Survived'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-71702e35e677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Survived'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tr_te = []\n",
    "for i in range(1,50):     \n",
    "    m = RandomForestClassifier(n_estimators=i)\n",
    "    m.fit(x_train, list(y_train.Survived));\n",
    "    \n",
    "    train_score = m.score(x_train, list(y_train.Survived))\n",
    "    test_score = m.score(x_test, list(y_test.Survived))\n",
    "    \n",
    "    tr_te.append([train_score, test_score])\n",
    "\n",
    "print(max(tr_te), tr_te.index(max(tr_te)))\n",
    "plot_tr_te(list(map(list, zip(*tr_te))), \"n_estimators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth\n",
    "\n",
    "Doe nu hetzelfde voor max_depth! Neem een range die voor jou aannemelijk is. Doe daarna een 'voorspelling' over wat de beste range is om aan te passen in je parameters. \n",
    "\n",
    "### Actie! \n",
    "\n",
    "Ach de actie staat hierboven beschreven. Voer het nu uit! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-8b1e041c40ea>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8b1e041c40ea>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    m.fit(x_train, list(y_train.Survived));\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tr_te = []\n",
    "for i in range(1,50):     \n",
    "    m = RandomForestClassifier(# Vul de paramter hier in)\n",
    "    m.fit(x_train, list(y_train.Survived))\n",
    "    \n",
    "    train_score = m.score(x_train, list(y_train.Survived))\n",
    "    test_score = m.score(x_test, list(y_test.Survived))\n",
    "    \n",
    "    tr_te.append([train_score, test_score])\n",
    "\n",
    "    \n",
    "plot_tr_te(list(map(list, zip(*tr_te))), # Pas de naam van de paramter hier aan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features\n",
    "\n",
    "\n",
    "### Actie! \n",
    "\n",
    "Kijk hoe de parameter max_features zich gedraagd met verschillende input values. Wat vindt je voor informatie uit deze grafiek? Wat zegt dit over het tunen van deze paramater? \n",
    "\n",
    "Extra info over hoe sklearn omgaat met deze paramter: \n",
    "\n",
    "*Volgens de sklearn documentatie zal een forest altijd een split zoeken hoger dan de maximum aangegeven hoeveelheid features als ze geen geldige partitie kunnen vinden van de node samples.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-fd54bf47a845>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-fd54bf47a845>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    m.fit(x_train, list(y_train.Survived));\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tr_te = []\n",
    "for i in range(1,len(x_train.columns)):     \n",
    "    m = RandomForestClassifier(# Vul de parameter met value hier in)\n",
    "    m.fit(x_train, list(y_train.Survived))\n",
    "    \n",
    "    train_score = m.score(x_train, list(y_train.Survived))\n",
    "    test_score = m.score(x_test, list(y_test.Survived))\n",
    "    \n",
    "    tr_te.append([train_score, test_score])\n",
    "\n",
    "    \n",
    "plot_tr_te(list(map(list, zip(*tr_te))), # Pas de naam van de paramter hier aan)\n",
    "print(x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_sample_split\n",
    "\n",
    "### Actie! \n",
    "\n",
    "Kijk hoe de parameter min_sample_split zich gedraagd met verschillende input values. Wat vindt je voor informatie uit deze grafiek? Wat zegt dit over het tunen van deze paramater? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-d26b3f0f36ea>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d26b3f0f36ea>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    m.fit(x_train, list(y_train.Survived));\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tr_te = []\n",
    "\n",
    "min_samples_leafs = np.linspace(0.1, 0.8, 5, endpoint=True)\n",
    "\n",
    "for i in min_samples_leafs:     \n",
    "    m = RandomForestClassifier(# Vul de parameter met instelling hier in)\n",
    "    m.fit(x_train, list(y_train.Survived));\n",
    "    \n",
    "    train_score = m.score(x_train, list(y_train.Survived))\n",
    "    test_score = m.score(x_test, list(y_test.Survived))\n",
    "    \n",
    "    tr_te.append([train_score, test_score])\n",
    "\n",
    "    \n",
    "plot_tr_te(list(map(list, zip(*tr_te))), # Pas de naam van de paramter hier aan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criterion\n",
    "\n",
    "Doe dit ook voor de Criterion! Gini of entropy, kan je zien welke beter is? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-545406405cfe>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-545406405cfe>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    crit = # Vul hier de criteria in!\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tr_te = []\n",
    "\n",
    "crit = # Vul hier de criteria in! \n",
    "\n",
    "for i in crit:     \n",
    "    m = RandomForestClassifier(# Vul hier de paramter waardes in)\n",
    "    m.fit(x_train, list(y_train.Survived));\n",
    "    \n",
    "    train_score = m.score(x_train, list(y_train.Survived))\n",
    "    test_score = m.score(x_test, list(y_test.Survived))\n",
    "    \n",
    "    tr_te.append([train_score, test_score])\n",
    "\n",
    "    \n",
    "train = list(map(list, zip(*tr_te)))[0]\n",
    "test = list(map(list, zip(*tr_te)))[1]\n",
    "\n",
    "print(\"Entropy, training set: {}, test set: {}\".format( train[0], test[0]))\n",
    "print(\"Gini,    training set: {}, test set: {}\".format( train[1], test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve \n",
    "\n",
    "Nog algemeen de ROC curve. Hier hoef je niets mee te doen. Slechts ter orientatie. \n",
    "\n",
    "[link naar scikit roc curve](https://scikit-learn.org/stable/auto_examples/plot_roc_curve_visualization_api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'Survived'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a92c775fa249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Survived'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "m = RandomForestClassifier()\n",
    "m.fit(x_train, list(y_train.Survived));\n",
    "\n",
    "plot_roc_curve(m, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Klinkt als een spannend science fiction boek? Bijna ja. Dit is een methode om je model te optimaliseren voor het voorspellen van je dataset. Je ben namelijk op zoek naar de OPTIMALE parameters! Hierboven hebben we al een en ander uitegezocht. Maar er is nog meer wat we kunnen doen. We kunnen namelijk een willekeurige set aan paramter values maken en die testen op ons random forest! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actie! \n",
    "\n",
    "Neem een aantal waardes voor de parameters waarvan JIJ denkt dat ze een GOEDE range zijn voor het voorspellen van je dataset. Doe dit voor de volgende parameters: \n",
    "\n",
    "    'bootstrap'\n",
    "    'max_depth'\n",
    "    'max_features'\n",
    "    'min_samples_leaf'\n",
    "    'min_samples_split'\n",
    "    'n_estimators'\n",
    "    \n",
    "Als je denkt dat een van deze parameters geen toegevoegde waarde heeft bij het voorspellen van ons model, dan mag je deze er uit laten. Als je denkt, wow er mist er echt een die mijn model enorm gaat verbeteren, voeg deze dan toe met values. \n",
    "\n",
    "Een advies voor n_estimators is bijvoorbeeld: \n",
    "\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-db737f5e2889>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-db737f5e2889>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    'max_features': ['auto', 'sqrt'],\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "random_parameters = {'bootstrap': [True, False],\n",
    "                     'max_depth': [# Vul values in ],\n",
    "                     'criterion': [# Vul values in]\n",
    "                     'min_samples_leaf': [# Vul values in],\n",
    "                     'min_samples_split': [# Vul values in],\n",
    "                     'n_estimators': [#Vul values in]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oke nu kunnen we deze testen! \n",
    "\n",
    "Dit is nu nog in proces. Mocht je zover zijn dan moet je even de docenten bereiken. Wellicht doen we dit klassikaal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kijk wat de beste parameters zijn\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
